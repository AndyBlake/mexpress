#!/bin/bash

### Program flow:
## - get tumor type
## - build url based on user input
## - wget the necessary file name(s)
## - check if the files already exist locally
## - if there are new or updated files available, download them
## - unzip the files
## - process them using the appropriate R script so they're ready to
##   be uploaded

function usage
{
    echo
    echo "Usage: downloadTCGAdata -t tumorType -f fullTumorName -a path/to/gene/annotation/file -n path/to/TCGA/gene/names/file"
    echo
}

tumorType=
fullTumorTypeName=
geneAnnotationFile=
geneNamesFile=
if [ "$1" == "" ]; then
    usage
    exit 1
fi
while [ "$1" != "" ]; do
    case $1 in
        -t | --tumor )              shift
                                    tumorType=$1
                                    ;;
        -f | --fullname )           shift
                                    fullTumorTypeName=$1
                                    ;;
        -a | --geneAnnotationFile ) shift
                                    geneAnnotationFile=$1
                                    ;;
        -n | --geneNamesFile )      shift
                                    geneNamesFile=$1
                                    ;;
        * )                         usage
                                    exit 1
    esac
    shift
done

echo "tumor = ${tumorType}"
echo "full name = ${fullTumorTypeName}"

if [ ${tumorType} == "" ] || [ ${fullTumorTypeName} == "" ] || [ ${geneAnnotationFile} == "" ] || [ ${geneNamesFile} == "" ]; then
    usage
    exit 1
fi

# Download the most recent version of the TCGA metadata.
echo "checking metadata..."
# The metadata file contains information on every single sample
# in the TCGA database.
if [ -f metadata.current.txt ]; then
    wget -q -N https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/other/metadata/metadata.current.txt
else
    wget -q -S https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/other/metadata/metadata.current.txt
fi

if [ ! -d ${tumorType} ]; then
    mkdir ${tumorType}
fi

echo "checking RNASeqV2 data..."
# Download the RNASeqV2 data.
# Start by finding the latest version of the expression data:
url="https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/tumor/${tumorType}/cgcc/unc.edu/illuminahiseq_rnaseqv2/rnaseqv2/?C=M;O=A"
fileName=$(wget -q -O - ${url} | grep -o -E "\"unc\.edu_.+Level_3.+\.tar.gz\"" | tail -1)
fileName=${fileName//\"/}
dirName=${fileName%.tar.gz}

if [ -d ${tumorType}/${dirName} ]; then
    echo "There is no new TCGA expression (RNASeqV2) data available."
else
    url=${url%?C=M;O=A}
    url=${url}${fileName}
    wget -q -O "${tumorType}/${fileName}" $url
    tar -zxf "${tumorType}/${fileName}" -C "${tumorType}"
    rm "${tumorType}/${fileName}"
    rm "${tumorType}/${dirName}/"*.txt "${tumorType}/${dirName}/"*isoforms* "${tumorType}/${dirName}/"*.rsem.genes.results
    Rscript processTCGArnaseqv2.R "${tumorType}" "${fullTumorTypeName}" "${dirName}"
    mv *_expression_"${tumorType}".sql "${tumorType}"/.
    mv tcga_rnaseqv2_data_"${tumorType}".txt "${tumorType}"/.
    # Clean up the TCGA data. We have combined the data in one file,
    # so we don't need the separate file anymore.
    # This will save a lot of disk space on the server.
    # The folder is not removed, as it's used to check which version of
    # the data has been downloaded.
    rm "${tumorType}/${dirName}"/*
    echo "${tumorType}" >> upload_expression.txt
fi

echo "checking HumanMethylation450 data..."
# Download the Infinium 450k DNA methylation data.
url=https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/tumor/${tumorType}/cgcc/jhu-usc.edu/humanmethylation450/methylation/
fileNames=(`wget -q -O - ${url} | grep -o -E "\"jhu-usc\.edu_.+Level_3.+\.tar.gz\""`)
downloadedInfiniumFileCount=0
downloadedFiles=()
for i in "${fileNames[@]}"; do
    fileName=
    fileName=${i//\"/}
    dirName=${fileName%.tar.gz}
    # Check if the folder already exists locally.
    # If it doesn't: download the methylation data.
    if [ ! -d ${tumorType}/${dirName} ]; then
        urli=${url}${fileName}
        downloadedFiles+=("${fileName}")
        wget -q -O "${tumorType}/${fileName}" $urli &
        downloadedInfiniumFileCount=`expr $downloadedInfiniumFileCount + 1`
    fi
    while (( $(jobs | wc -l) >= 6 )); do
        sleep 0.1
        jobs > /dev/null
    done
done
wait
if [ $downloadedInfiniumFileCount -eq 0 ]; then
    # No files were downloaded, meaning that all the data was already
    # available locally.
    echo "There is no new TCGA DNA methylation (HumanMethylation450) data available."
else
    echo "New TCGA DNA methylation (HumanMethylation450) data found!"
    for i in "${downloadedFiles[@]}"; do
        fileName=
        fileName=${i//\"/}
        tar -zxf "${tumorType}/${fileName}" -C "${tumorType}" &
        while (( $(jobs | wc -l) >= 6 )); do
            sleep 0.1
            jobs > /dev/null
        done
    done
    wait
    # Create a temporary folder to store all the methylation data together,
    # ready for processing.
    mkdir "${tumorType}"/humanMethylation450temp/
    for i in "${downloadedFiles[@]}"; do
        fileName=
        fileName=${i//\"/}
        dirName=${fileName%.tar.gz}
        rm "${tumorType}/${fileName}"
        mv "${tumorType}/${dirName}"/jhu-usc.edu_* ${tumorType}/humanMethylation450temp/.
        # Clean up any remaining files in the TCGA data folder
        rm "${tumorType}/${dirName}"/*
    done
    Rscript processTCGAhumanmethylation450.R "${tumorType}" "${fullTumorTypeName}" humanMethylation450temp
    # Clean up the TCGA data. We have combined the data in one file,
    # so we don't need the separate files anymore.
    rm -rf "${tumorType}"/humanMethylation450temp
    echo "${tumorType}" >> upload_methylation.txt
fi

echo "checking CNV data..."
# Download the CNV data.
# We need two types of directories from TCGA:
# 1. The first one (*Level_3*.tar.gz) contains the actual CNV data file
#    (*.hg19.seq.txt) and a file that links the data file name to an
#    identifier (MANIFEST.TXT),
# 2. The second one (*mage-tab*.tar.gz) contains a file that links the
#    identifier to the TCGA sample barcode (which is used as the sample
#    name in MEXPRESS)
#
url="https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/tumor/${tumorType}/cgcc/broad.mit.edu/genome_wide_snp_6/snp/"
fileNames=(`wget -q -O - ${url} | grep -o -E "\"broad\.mit\.edu_.+Level_3.+.0/\""`)
downloadedFileCount=0
downloadedFiles=()
for i in "${fileNames[@]}"; do
    dirName=${i//\"/}
    fileName=${dirName}
    fileName=${fileName//\//.tar.gz}
    # Check if the folder already exists locally.
    # If it doesn't: download the CNV data.
    if [ ! -d ${tumorType}/${dirName} ]; then
        urli=${url}${fileName}
        downloadedFiles+=("${fileName}")
        wget -q -O- $urli | tar -xz -C "${tumorType}" &
        downloadedFileCount=`expr $downloadedFileCount + 1`
    fi
    while (( $(jobs | wc -l) >= 6 )); do
        sleep 0.1
        jobs > /dev/null
    done
done
wait
if [ ${#fileNames[@]} -eq 0 ]; then
    echo "No TCGA CNV found."
elif [ $downloadedFileCount -eq 0 ]; then
    # No files were downloaded, meaning that all the data was already
    # available locally.
    echo "There is no new TCGA CNV data available."
else
    echo "New TCGA CNV data found!"
    # Go through the extracted folders and:
    # 1. Remove the files we don't need.
    # 2. Download the appropriate mage-tab file (the mage-tab files
    #    and the data folders are linked through their names)
    for i in "${downloadedFiles[@]}"; do
        fileName=${i}
        dirName=${fileName%.tar.gz}
        # Remove files we don't need.
        rm "${tumorType}/${dirName}"/*.hg18.seg.txt
        rm "${tumorType}/${dirName}"/*_hg18.seg.txt
        rm "${tumorType}/${dirName}"/*_hg19.seg.txt
        rm "${tumorType}/${dirName}"/README_DCC.txt
        rm "${tumorType}/${dirName}"/MANIFEST.txt
        if [ -f "${tumorType}/${dirName}"/CHANGES_DCC.txt ]; then
            rm "${tumorType}/${dirName}"/CHANGES_DCC.txt
        fi
        # Download the mage-tabe file.
        # Start by extracting the identifier that links the data folders
        # and mage-tab files from the data folder name.
        identifier=${dirName%.0}
        identifier=${identifier//broad\.mit\.edu_*Level_3\.*\./}
        mageTabUrl="${url}broad.mit.edu_${tumorType^^}.Genome_Wide_SNP_6.mage-tab.1.${identifier}.0.tar.gz"
        mageDir="broad.mit.edu_${tumorType}.Genome_Wide_SNP_6.mage-tab.1.${identifier}.0"
        if [ ! -d "${tumorType}/${mageDir}" ]; then
            wget -q -O- "${mageTabUrl}" | tar -xz -C "${tumorType}" &
        fi
        while (( $(jobs | wc -l) >= 6 )); do
            sleep 0.1
            jobs > /dev/null
        done
    done
    wait
    # Remove the mage-tab files we don't need.
    rm "${tumorType}"/*mage-tab*/CHANGES_DCC.txt
    rm "${tumorType}"/*mage-tab*/DESCRIPTION.txt
    rm "${tumorType}"/*mage-tab*/README_DCC.txt
    rm "${tumorType}"/*mage-tab*/MANIFEST.txt
    rm "${tumorType}"/*mage-tab*/*.idf.txt
    # Run the R script to process the CNV data.
    Rscript processTCGAcnv.R "${tumorType}" "${fullTumorTypeName}" "${geneAnnotationFile}" "${geneNamesFile}"
    echo "${tumorType}" >> upload_cnv.txt
fi

# Download the most recent version of the clinical patient data.
echo "checking clinical patient data..."
if [ ! -d "${tumorType}/clinicalPatient/" ]; then
    mkdir "${tumorType}/clinicalPatient/"
fi
url=https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/tumor/${tumorType}/bcr/biotab/clin/nationwidechildrens.org_clinical_patient_${tumorType}.txt
if [ -f "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" ]; then
    wget -q -N -O "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" $url
else
    wget -q -S -O "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" $url
fi
# Check if the downloaded file contains data
# (sometimes the download fails resulting in an empty file instead of an error)
if [ ! -s "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" ]; then
    echo "download failed!"
    echo "retrying..."
    count=0
    while [ $count -le 10 ]; do
        sleep 10
        count=$(($count+1))
        wget -q -S -O "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" $url
        if [ -s "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" ]; then
            echo "success!"
            break
        fi
    done
    if [ ! -s "${tumorType}/clinicalPatient/nationwidechildrens.org_clinical_patient_${tumorType}.txt" ]; then
        echo
        echo "could not download the clinical annotation data"
        echo
        exit 1
    fi
fi
# Extract the columns we are interested in. This is different
# for each cancer type. The column names we are interested in
# can be found in the file clinicalPatientData.txt.
Rscript processTCGAclinicalPatientData.R "${tumorType}" clinicalPatient

# Download the most recent version of the sample slide data.
echo "checking sample slide data..."
if [ ! -d "${tumorType}/sampleSlide/" ]; then
    mkdir "${tumorType}/sampleSlide/"
fi
url=https://tcga-data.nci.nih.gov/tcgafiles/ftp_auth/distro_ftpusers/anonymous/tumor/${tumorType}/bcr/biotab/clin/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt
if [ -f "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" ]; then
    wget -q -N -O "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" $url
else
    wget -q -S -O "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" $url
fi
# Check if the downloaded file contains data
# (sometimes the download fails resulting in an empty file instead of an error)
if [ ! -s "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" ]; then
    echo "download failed!"
    echo "retrying..."
    count=0
    while [ $count -le 10 ]; do
        sleep 10
        count=$(($count+1))
        wget -q -S -O "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" $url
        if [ -s "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" ]; then
            echo "success!"
            break
        fi
    done
    if [ ! -s "${tumorType}/sampleSlide/nationwidechildrens.org_biospecimen_slide_${tumorType}.txt" ]; then
        echo
        echo "could not download the sample annotation data"
        echo
        exit 1
    fi
fi
# Extract the columns we are interested in. This is different for each cancer type.
# The column names we are interested in can be found in the file sampleSlideData.txt.
Rscript processTCGAsampleSlideData.R "${tumorType}" sampleSlide
